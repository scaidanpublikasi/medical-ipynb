{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12617633,"sourceType":"datasetVersion","datasetId":7963140},{"sourceId":504355,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":400602,"modelId":418819}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full standalone inference + visualization script for test set\nimport os\nimport numpy as np\nimport nibabel as nib\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, Orientationd,\n    ResizeWithPadOrCropd, NormalizeIntensityd, ToTensord\n)\nfrom monai.data import Dataset as MonaiDataset\nfrom monai.networks.nets import UNet\nfrom monai.inferers import sliding_window_inference\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n\n# ----------------- USER CONFIG -----------------\nimage_test_dir = \"/kaggle/input/costa-adam/imagesTs\"   # path ke folder image test\nlabel_test_dir = \"/kaggle/input/costa-adam/labelsTs\"   # path ke folder label test\nmodel_path = \"/kaggle/input/model_seg_brain_vessel/pytorch/default/1/model.pt\"                # path model tersimpan\nout_pred_dir = \"/kaggle/working/predictions\"           # folder untuk nifti prediksi\nvis_dir = \"/kaggle/working/predictions_vis\"           # folder visualisasi\nbatch_size = 1\ninput_size = (128, 128, 128)   # harus sama seperti saat training / atau sesuai kebutuhan\nthreshold = 0.5\nnum_vis = 6                    # berapa sample test yang ingin divisualisasi (0=semua)\n# ------------------------------------------------\n\nos.makedirs(out_pred_dir, exist_ok=True)\nos.makedirs(vis_dir, exist_ok=True)\n\n# ---- find test image & label files ----\ndef list_nii_files(folder):\n    files = [f for f in os.listdir(folder) if (f.endswith(\".nii\") or f.endswith(\".nii.gz\"))]\n    files = sorted(files)\n    return [os.path.join(folder, f) for f in files]\n\ntest_paths = list_nii_files(image_test_dir)\nlabel_test_paths = list_nii_files(label_test_dir)\n\nif len(test_paths) == 0:\n    raise FileNotFoundError(f\"Tidak menemukan file nii di {image_test_dir}\")\nif len(label_test_paths) == 0:\n    raise FileNotFoundError(f\"Tidak menemukan file nii di {label_test_dir}\")\nif len(test_paths) != len(label_test_paths):\n    print(\"Peringatan: jumlah image dan label test berbeda. Akan meng-zip sampai panjang minimum.\")\nmin_len = min(len(test_paths), len(label_test_paths))\ntest_paths = test_paths[:min_len]\nlabel_test_paths = label_test_paths[:min_len]\n\nprint(f\"Jumlah sample test: {len(test_paths)}\")\n\n# ---- transforms & dataset ----\ntest_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),              # will load as numpy array\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),    # ensure channel dim first\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=input_size),\n    NormalizeIntensityd(keys=\"image\"),\n    ToTensord(keys=[\"image\", \"label\"])\n])\n\ntest_dicts = [{\"image\": img, \"label\": lbl} for img, lbl in zip(test_paths, label_test_paths)]\ntest_ds = MonaiDataset(test_dicts, transform=test_transforms)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# ---- device & model (sama arsitektur dengan training) ----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(32, 64, 128, 256, 512),\n    strides=(2, 2, 2, 2),\n    num_res_units=2\n).to(device)\n\nif not os.path.exists(model_path):\n    raise FileNotFoundError(f\"Model file tidak ditemukan di {model_path}. Pastikan file ada.\")\nmodel.load_state_dict(torch.load(model_path, map_location=device))\nmodel.eval()\nprint(\"Model loaded:\", model_path)\n\n# ---- inference loop, simpan nifti, hitung metrik ----\ntest_metrics = {\"Dice\": [], \"IoU\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []}\n\nwith torch.no_grad():\n    for i, batch in enumerate(test_loader):\n        x = batch[\"image\"].to(device)        # tensor shape (B, C, D, H, W)\n        # Convert original volumes (pre-transform) to get affine:\n        # We will read affine using nib from original file list (test_paths[i]) BEFORE transform resizing,\n        # so predictions are saved with the original affine if we resample back. For simplicity, we'll save with identity affine\n        # OR better: read input file to get affine (original). We'll use original file affine here:\n        orig_img_path = test_paths[i]\n        orig_affine = nib.load(orig_img_path).affine\n\n        # sliding window inference (returns logits) -> apply sigmoid -> threshold\n        pred = sliding_window_inference(x, roi_size=input_size, sw_batch_size=1, predictor=model)\n        pred_np = torch.sigmoid(pred).cpu().numpy()      # shape (B, 1, D, H, W)\n        pred_np = pred_np[0, 0]                          # (D, H, W)\n        pred_bin = (pred_np > threshold).astype(np.uint8)\n\n        # Save prediction nifti using original affine (note: we resized in transforms to input_size,\n        # so spatial shape equals input_size; if you want to save in original voxel grid you must resample back)\n        save_path = os.path.join(out_pred_dir, f\"prediction_{i}.nii.gz\")\n        nib.save(nib.Nifti1Image(pred_bin.astype(np.uint8), affine=orig_affine), save_path)\n\n        # get ground truth and flatten for metrics (note: label was resized to input_size by transform)\n        y_true = batch[\"label\"].cpu().numpy()[0, 0].astype(np.uint8).flatten()\n        y_pred_flat = pred_bin.flatten()\n\n        # handle degenerate cases for precision/recall when all zeros\n        try:\n            test_metrics[\"Dice\"].append(f1_score(y_true, y_pred_flat, zero_division=0))\n            test_metrics[\"IoU\"].append(jaccard_score(y_true, y_pred_flat, zero_division=0))\n            test_metrics[\"Accuracy\"].append(accuracy_score(y_true, y_pred_flat))\n            test_metrics[\"Precision\"].append(precision_score(y_true, y_pred_flat, zero_division=0))\n            test_metrics[\"Recall\"].append(recall_score(y_true, y_pred_flat, zero_division=0))\n            test_metrics[\"F1\"].append(f1_score(y_true, y_pred_flat, zero_division=0))\n        except Exception as e:\n            print(f\"Error menghitung metrik untuk sample {i}: {e}\")\n\n        # --- VISUALISASI per-sample ---\n        # Ambil volume hasil transform (yang ukurannya input_size)\n        image_vol = batch[\"image\"].cpu().numpy()[0, 0]  # (D, H, W)\n        label_vol = batch[\"label\"].cpu().numpy()[0, 0]  # (D, H, W)\n\n        mid_slice_idx = image_vol.shape[0] // 2\n        slice_sums = pred_bin.sum(axis=(1, 2))\n        max_slice_idx = int(np.argmax(slice_sums)) if slice_sums.sum() > 0 else mid_slice_idx\n        slices_to_show = sorted(set([mid_slice_idx, max_slice_idx]))\n\n        for s_idx in slices_to_show:\n            img_slice = image_vol[s_idx]\n            lbl_slice = label_vol[s_idx]\n            prd_slice = pred_bin[s_idx]\n\n            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n            axes[0].imshow(img_slice, cmap=\"gray\")\n            axes[0].set_title(f\"Image (slice {s_idx})\")\n            axes[0].axis(\"off\")\n\n            axes[1].imshow(lbl_slice, cmap=\"gray\")\n            axes[1].set_title(\"Ground Truth\")\n            axes[1].axis(\"off\")\n\n            axes[2].imshow(prd_slice, cmap=\"gray\")\n            axes[2].set_title(\"Prediction (binary)\")\n            axes[2].axis(\"off\")\n\n            axes[3].imshow(img_slice, cmap=\"gray\")\n            axes[3].imshow(np.ma.masked_where(lbl_slice == 0, lbl_slice), cmap=\"Greens\", alpha=0.4)\n            axes[3].imshow(np.ma.masked_where(prd_slice == 0, prd_slice), cmap=\"Reds\", alpha=0.4)\n            axes[3].set_title(\"Overlay: GT(green) / Pred(red)\")\n            axes[3].axis(\"off\")\n\n            plt.suptitle(f\"Test sample {i} â€” slice {s_idx}\")\n            plt.tight_layout(rect=[0, 0, 1, 0.95])\n\n            out_path = os.path.join(vis_dir, f\"test_{i}_slice_{s_idx}.png\")\n            plt.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n            plt.show()\n            plt.close(fig)\n\n        # stop jika sudah mencapai jumlah visualisasi yang diminta\n        if num_vis > 0 and i + 1 >= num_vis:\n            break\n\n# ---- print aggregated test metrics ----\nprint(\"\\nAggregated Test Metrics (mean across volumes):\")\nfor k, v in test_metrics.items():\n    if len(v) > 0:\n        print(f\"{k}: {np.mean(v):.4f} (n={len(v)})\")\n    else:\n        print(f\"{k}: - (no data)\")\n\nprint(f\"\\nPrediksi nifti disimpan di: {out_pred_dir}\")\nprint(f\"Visualisasi disimpan di: {vis_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport nibabel as nib\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, Orientationd,\n    ResizeWithPadOrCropd, NormalizeIntensityd, ToTensord\n)\nfrom monai.data import Dataset as MonaiDataset\nfrom monai.networks.nets import UNet\nfrom monai.inferers import sliding_window_inference\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n\nimage_file_path = \"/kaggle/input/costa-adam/imagesTs/10001-TOF_ADAM.nii\"\nlabel_file_path = \"/kaggle/input/costa-adam/labelsTs/10001-TOF_ADAM.nii\"\nmodel_path = \"/kaggle/input/model_seg_brain_vessel/pytorch/default/1/model.pt\"\n\nout_pred_dir = \"/kaggle/working/predictions_single\"        \nvis_dir = \"/kaggle/working/predictions_vis_single\"        \ninput_size = (128, 128, 128)\nthreshold = 0.5\n\n\nos.makedirs(out_pred_dir, exist_ok=True)\nos.makedirs(vis_dir, exist_ok=True)\n\nif not os.path.exists(image_file_path):\n    raise FileNotFoundError(f\"File image tidak ditemukan di {image_file_path}\")\nif not os.path.exists(model_path):\n    raise FileNotFoundError(f\"Model file tidak ditemukan di {model_path}. Pastikan file ada.\")\n\ntransform_keys = [\"image\", \"label\"]\n\ntest_transforms = Compose([\n    LoadImaged(keys=transform_keys, allow_missing_keys=True), # Izinkan jika 'label' tidak ada\n    EnsureChannelFirstd(keys=transform_keys, allow_missing_keys=True),\n    Orientationd(keys=transform_keys, axcodes=\"RAS\", allow_missing_keys=True),\n    ResizeWithPadOrCropd(keys=transform_keys, spatial_size=input_size, allow_missing_keys=True),\n    NormalizeIntensityd(keys=\"image\"), # Selalu normalisasi image\n    ToTensord(keys=transform_keys, allow_missing_keys=True)\n])\n\ndata_dict = {\"image\": image_file_path}\n\nif label_file_path:\n    if not os.path.exists(label_file_path):\n        print(f\"Peringatan: File label {label_file_path} tidak ditemukan. Melanjutkan tanpa label.\")\n        label_file_path = None\n    else:\n        data_dict[\"label\"] = label_file_path\n        print(f\"File label ditemukan: {label_file_path}\")\nelse:\n     print(\"Tidak ada file label. Hanya akan melakukan prediksi (tanpa metrik/overlay GT).\")\n\nprint(\"Memuat dan mentransformasi data...\")\ntry:\n    transformed_data = test_transforms(data_dict)\n    print(\"Data loaded dan ditransformasi.\")\nexcept Exception as e:\n    print(f\"Error saat memuat/transformasi data: {e}\")\n    if label_file_path:\n        print(\"Mencoba lagi tanpa label...\")\n        label_file_path = None\n        data_dict.pop(\"label\", None)\n        test_transforms = Compose([\n            LoadImaged(keys=\"image\"),\n            EnsureChannelFirstd(keys=\"image\"),\n            Orientationd(keys=\"image\", axcodes=\"RAS\"),\n            ResizeWithPadOrCropd(keys=\"image\", spatial_size=input_size),\n            NormalizeIntensityd(keys=\"image\"),\n            ToTensord(keys=\"image\")\n        ])\n        transformed_data = test_transforms(data_dict)\n        print(\"Data loaded (hanya image).\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(32, 64, 128, 256, 512),\n    strides=(2, 2, 2, 2),\n    num_res_units=2\n).to(device)\n\nmodel.load_state_dict(torch.load(model_path, map_location=device))\nmodel.eval()\nprint(\"Model loaded:\", model_path)\n\n\nwith torch.no_grad():\n\n    x = transformed_data[\"image\"].unsqueeze(0).to(device)\n\n    orig_affine = nib.load(image_file_path).affine\n\n    base_name = os.path.basename(image_file_path).split('.')[0]\n\n    print(f\"Menjalankan inference untuk {base_name}...\")\n    \n    pred = sliding_window_inference(x, roi_size=input_size, sw_batch_size=1, predictor=model)\n    pred_np = torch.sigmoid(pred).cpu().numpy()      \n    pred_np = pred_np[0, 0]                       \n    pred_bin = (pred_np > threshold).astype(np.uint8)\n\n    save_path = os.path.join(out_pred_dir, f\"prediction_{base_name}.nii.gz\")\n    nib.save(nib.Nifti1Image(pred_bin.astype(np.uint8), affine=orig_affine), save_path)\n    print(f\"Prediksi nifti disimpan di: {save_path}\")\n\n    image_vol = transformed_data[\"image\"].cpu().numpy()[0] # (D, H, W)\n\n    mid_slice_idx = image_vol.shape[0] // 2\n    slice_sums = pred_bin.sum(axis=(1, 2))\n    max_slice_idx = int(np.argmax(slice_sums)) if slice_sums.sum() > 0 else mid_slice_idx\n    slices_to_show = sorted(set([mid_slice_idx, max_slice_idx]))\n\n    if label_file_path and \"label\" in transformed_data:\n        print(\"Label ditemukan. Menghitung metrik dan membuat visualisasi 4-panel...\")\n        \n        # Ambil ground truth\n        label_vol = transformed_data[\"label\"].cpu().numpy()[0] # (D, H, W)\n        y_true = label_vol.astype(np.uint8).flatten()\n        y_pred_flat = pred_bin.flatten()\n        \n        # Hitung dan print metrik\n        try:\n            dice = f1_score(y_true, y_pred_flat, zero_division=0)\n            iou = jaccard_score(y_true, y_pred_flat, zero_division=0)\n            accuracy = accuracy_score(y_true, y_pred_flat)\n            precision = precision_score(y_true, y_pred_flat, zero_division=0)\n            recall = recall_score(y_true, y_pred_flat, zero_division=0)\n            \n            print(\"\\nMetrics for this file:\")\n            print(f\"  Dice (F1): {dice:.4f}\")\n            print(f\"  IoU (Jaccard): {iou:.4f}\")\n            print(f\"  Accuracy: {accuracy:.4f}\")\n            print(f\"  Precision: {precision:.4f}\")\n            print(f\"  Recall: {recall:.4f}\")\n\n        except Exception as e:\n            print(f\"Error menghitung metrik: {e}\")\n\n        # --- VISUALISASI (dengan label) ---\n        for s_idx in slices_to_show:\n            img_slice = image_vol[s_idx]\n            lbl_slice = label_vol[s_idx]\n            prd_slice = pred_bin[s_idx]\n\n            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n            axes[0].imshow(img_slice, cmap=\"gray\")\n            axes[0].set_title(f\"Image (slice {s_idx})\")\n            axes[0].axis(\"off\")\n\n            axes[1].imshow(lbl_slice, cmap=\"gray\")\n            axes[1].set_title(\"Ground Truth\")\n            axes[1].axis(\"off\")\n\n            axes[2].imshow(prd_slice, cmap=\"gray\")\n            axes[2].set_title(\"Prediction (binary)\")\n            axes[2].axis(\"off\")\n\n            axes[3].imshow(img_slice, cmap=\"gray\")\n            axes[3].imshow(np.ma.masked_where(lbl_slice == 0, lbl_slice), cmap=\"Greens\", alpha=0.4)\n            axes[3].imshow(np.ma.masked_where(prd_slice == 0, prd_slice), cmap=\"Reds\", alpha=0.4)\n            axes[3].set_title(\"Overlay: GT(green) / Pred(red)\")\n            axes[3].axis(\"off\")\n\n            plt.suptitle(f\"Sample: {base_name} â€” slice {s_idx}\")\n            plt.tight_layout(rect=[0, 0, 1, 0.95])\n\n            out_path = os.path.join(vis_dir, f\"vis_{base_name}_slice_{s_idx}.png\")\n            plt.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n            plt.show()\n            plt.close(fig)\n        \n        print(f\"Visualisasi (4-panel) disimpan di: {vis_dir}\")\n\n    else:\n        # --- Visualisasi (TANPA label) ---\n        print(\"Label tidak ditemukan. Membuat visualisasi 3-panel...\")\n\n        for s_idx in slices_to_show:\n            img_slice = image_vol[s_idx]\n            prd_slice = pred_bin[s_idx]\n\n            fig, axes = plt.subplots(1, 3, figsize=(12, 4)) # Ukuran 1x3\n            axes[0].imshow(img_slice, cmap=\"gray\")\n            axes[0].set_title(f\"Image (slice {s_idx})\")\n            axes[0].axis(\"off\")\n\n            axes[1].imshow(prd_slice, cmap=\"gray\")\n            axes[1].set_title(\"Prediction (binary)\")\n            axes[1].axis(\"off\")\n\n            axes[2].imshow(img_slice, cmap=\"gray\")\n            axes[2].imshow(np.ma.masked_where(prd_slice == 0, prd_slice), cmap=\"Reds\", alpha=0.5) # Overlay prediksi\n            axes[2].set_title(\"Overlay: Pred(red)\")\n            axes[2].axis(\"off\")\n\n            plt.suptitle(f\"Sample: {base_name} â€” slice {s_idx}\")\n            plt.tight_layout(rect=[0, 0, 1, 0.95])\n            \n            out_path = os.path.join(vis_dir, f\"vis_{base_name}_slice_{s_idx}.png\")\n            plt.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n            plt.show()\n            plt.close(fig)\n\n        print(f\"Visualisasi (3-panel) disimpan di: {vis_dir}\")\n\nprint(\"\\nSelesai.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}